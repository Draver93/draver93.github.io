{
  "tutorials": [
    {
      "id": "introduction",
      "title": "Introduction to FFStudio",
      "description": "See how FFStudio brings the full power of FFmpeg into a visual graph system for media engineers and developers.",
      "category": "Getting Started",
      "readTime": "8 min read",
      "date": "September 5, 2025",
      "icon": "fas fa-project-diagram",
      "image": "tutorials/getting-started.png",
      "tags": ["ffmpeg", "developers", "media", "workflow"],
      "intro": "FFmpeg is the foundation of modern media processing. It powers transcoding farms, streaming services, broadcast automation, and countless editing pipelines. But building and maintaining large, reliable FFmpeg workflows often means juggling complex commands, testing variations, and dealing with long scripts. FFStudio was created to change that — a graph-based interface that exposes *all* of FFmpeg, while giving engineers clarity, flexibility, and speed.",
      "sections": [
        {
          "title": "Installation guide",
          "content": "",
          "youtubeVideo": "https://www.youtube.com/watch?v=Hb-KCELzTec"
        },
        {
          "title": "The Challenge of CLI Workflows",
          "content": "Here’s a typical command you might use in FFmpeg:\n\n```bash ffmpeg -i input.mp4 -i logo.png -filter_complex \"[0:v]scale=1280:720[v0]; [v0][1:v]overlay=10:10:enable='between(t,0,20)'[vout]\" -map \"[vout]\" -map 0:a:0 -c:v libx264 -b:v 2500k -c:a aac -b:a 128k output.mp4```\n\nThis one command scales a video to 720p, overlays a logo for the first 20 seconds, keeps the first audio track, and encodes with H.264 + AAC. It’s powerful — but it’s also hard to read, debug, or extend when your pipeline grows to multiple filters, mappings, or outputs.",
          "image": "tutorials/cli-long-command.png" 
        },
        {
          "title": "The FFStudio Approach",
          "content": "In FFStudio, the same operation is built visually:\n- **Input Node** → your video file.\n- **Filter Nodes** → scale, then overlay.\n- **Encoder Nodes** → H.264 for video, AAC for audio.\n- **Output Node** → final MP4.\n\nInstead of parsing a long string, you *see* the workflow as a connected graph. Each node is configured with the same options FFmpeg exposes, but the structure is clear, reusable, and easy to extend.",
          "image": "tutorials/graph-scale-overlay.png"
        },
        {
          "title": "Parsing FFmpeg Into Nodes",
          "content": "FFStudio doesn’t just wrap a single FFmpeg binary. It understands *your* FFmpeg build. By running commands like `ffmpeg -h full` or `ffmpeg -h encoder=libx264`, FFStudio parses the documentation directly from FFmpeg’s self-describing preprocessor system. That means:\n\n- Every codec, filter, muxer, and option in your FFmpeg build is discoverable.\n- Node inputs, outputs, and parameters are generated automatically.\n- Custom FFmpeg builds with proprietary or experimental modules become first-class citizens in the UI.\n\nThis way, FFStudio stays in sync with FFmpeg — no feature hidden, no lock-in.",
          "image": "tutorials/ffmpeg-parsing.png"
        },
        {
          "title": "Bring Your Own FFmpeg",
          "content": "You’re not limited to the version of FFmpeg bundled with the app. In FFStudio, you specify the path to the binary and its environment variables (like shared libraries). FFStudio then parses that binary and exposes all of its capabilities. For developers working with patched builds, new filters, or hardware acceleration modules, this means total freedom. Your custom FFmpeg becomes fully usable in a visual environment — no compromises.",
          "image": "tutorials/custom-ffmpeg.png"
          
        },
        {
          "title": "Who Benefits?",
          "content": "FFStudio is designed for:\n- **Media engineers** building and maintaining transcoding farms.\n- **Developers** integrating FFmpeg into larger processing pipelines.\n- **Researchers & enthusiasts** experimenting with new codecs or custom filters.\n\nInstead of wrestling with giant command strings, you design, save, and share workflows as visual graphs — reproducible and maintainable. FFStudio is not a toy GUI; it’s a productivity layer for raw FFmpeg."
        }
      ],
      "conclusion": "FFStudio combines the raw power of FFmpeg with the clarity of a graph-based workflow. By exposing every feature of your chosen FFmpeg build, it removes the guesswork and speeds up development. In the next tutorial, we’ll get hands-on: exploring the interface and creating your first workflow."
    },
    {
      "id": "ui-and-functionality",
      "title": "Navigating the FFStudio Interface",
      "description": "A deep dive into FFStudio’s UI: top bar, workflow sidebar, graph editor, player, and logs. Learn how to use every panel, menu, and button.",
      "category": "Getting Started",
      "readTime": "15 min read",
      "date": "September 6, 2025",
      "icon": "fas fa-window-maximize",
      "image": "tutorials/ui-overview-cover.png",
      "tags": ["interface", "graph", "player", "logs", "workflow"],
      "intro": "FFStudio is built for power and consistency. Instead of constantly changing layouts, the interface follows a fixed structure with a top bar, a right sidebar, and three core panels: Graph, Player, and Logs. Once you understand how these pieces work together, you’ll navigate complex workflows with ease.",
      "sections": [
        {
          "title": "Top Bar & Sidebar: The Core Layout",
          "content": "At the top, FFStudio always shows three tabs: **Graph**, **Player**, and **Logs**. These define your main workflow stages.\n\nOn the right, the **Workflows sidebar** lists all your saved workflows. Each workflow card shows:\n- Name, creation date, and FFmpeg binary path\n- Four actions: **Edit**, **Save**, **Export**, **Delete**\n\nAbove the list is **New Workflow**, and at the very bottom is the **Execute Graph** button — the main trigger for running your workflow. The sidebar can be hidden using the arrow next to 'Workflows'.\n\nThis fixed layout ensures you always know where things are, no matter how complex your project becomes.",
          "image": "tutorials/ui-layout.png"
        },
        {
          "title": "The Graph Panel",
          "content": "The **Graph tab** is the heart of FFStudio. It uses a Litegraph-based canvas to visually build FFmpeg pipelines.\n\nKey interactions:\n- **LMB + drag** (empty space): move viewport\n- **Scroll wheel**: zoom\n- **RMB (empty space)**: open context menu with all FFmpeg nodes\n- **Double LMB (empty space)**: search node by name\n- **LMB (node)**: select\n- **LMB + drag (node)**: move\n- **RMB (node)**: open node menu (clone, delete, description, color, properties)\n- **Collapse toggle**: top-left dot on node collapses into compact view\n\nConnections are strict — you can only link compatible nodes in the correct direction. This ensures generated FFmpeg commands are always structurally valid, even if parameters are misconfigured.",
          "image": "tutorials/ui-graph-panel.png"
        },
        {
          "title": "The Player Panel",
          "content": "The **Player tab** speeds up development by letting you preview workflow results without transcoding the full file.\n\nFeatures:\n- **Timeline navigation**: click to set playhead, or click+drag to create a range\n- **Segment rendering**: bottom-left green button encodes only the selected range (or a single frame if no range)\n- **Segment editing**: resize by dragging edges, move by dragging the middle, delete with the ✖ icon\n- **Viewport controls**: RMB+drag or scroll wheel to move timeline, Ctrl+Scroll to zoom\n- **Reset button** clears selection\n\nWith this, you can iterate quickly: test filters, verify overlays, and debug encoding steps before committing to full renders.",
          "image": "tutorials/ui-player-panel.png"
        },
        {
          "title": "The Logs Panel",
          "content": "The **Logs tab** provides full transparency into what FFStudio and FFmpeg are doing.\n\nFeatures:\n- Log levels: **red (error)**, **yellow (warning)**, **gray (debug)**, **green (success)**, **blue (info)**\n- Tab highlights red when a new error arrives\n- Each log entry includes timestamp and type\n- **Export logs** button (top-right)\n- **Clear logs** button to reset view\n\nThis is where you’ll copy commands, debug workflows, and verify FFmpeg’s exact behavior.",
          "image": "tutorials/ui-logs-panel.png"
        },
        {
          "title": "Workflow Creation & Caching",
          "content": "The first time you create a workflow with a new FFmpeg binary, FFStudio parses a large set of metadata — filters, codecs, muxers, and more. This can take time, but subsequent workflows reuse the cached data, so loading is much faster.\n\nDuring graph execution, a loading overlay appears. You can dismiss it by clicking outside the blur zone, continuing to interact with the graph and logs while transcoding runs in the background.",
          "image": "tutorials/ui-workflow-creation.png"
          
        }
      ],
      "conclusion": "By now, you’ve explored every permanent element of FFStudio’s interface. The top bar defines your workflow stage, the sidebar manages your projects, and the three main panels — Graph, Player, Logs — give you complete control over building, previewing, and executing pipelines. Next, we’ll dive deeper into working with nodes and constructing complex graphs."
    },
    {
      "id": "working-with-nodes",
      "title": "Working with Nodes in FFStudio",
      "description": "Learn how to add, configure, and connect nodes. Master the inspector panel to unlock the full power of FFmpeg inside FFStudio.",
      "category": "Building Workflows",
      "readTime": "18 min read",
      "date": "September 6, 2025",
      "icon": "fas fa-project-diagram",
      "image": "tutorials/nodes-cover.png",
      "tags": ["nodes", "graph", "inspector", "workflow"],
      "intro": "Nodes are the building blocks of FFStudio workflows. Each node represents an FFmpeg component — an input, a filter, a codec, or an output. By combining nodes visually, you construct complete transcoding pipelines without writing raw commands.",
      "sections": [
        {
          "title": "Adding Nodes",
          "content": "There are two main ways to add nodes:\n\n- **Right-click context menu**: RMB on empty space → choose from categorized list of FFmpeg components (inputs, filters, codecs, muxers, etc.)\n- **Search menu**: Double LMB on empty space → type node name and insert instantly\n\nNodes are auto-validated, meaning only compatible connections are allowed.",
          "image": "tutorials/nodes-adding.png"
        },
        {
          "title": "Connecting Nodes",
          "content": "Each node exposes **inputs and outputs** represented by connection points. FFStudio enforces correct wiring:\n- Filter, Inputs and Outputs can be connected only to Stream Selector\n- Inputs allow only demuxers and decoders. \n- Outputs allow only muxers and encoders. \n- Streams flow left-to-right (inputs → filters → encoders → outputs)\n\nDrag from one node’s output to another’s input to link them. Invalid links are automatically rejected.",
          "image": "tutorials/nodes-connecting.png"
        },
        {
          "title": "Inspector Panel",
          "content": "When you select a node, its full set of parameters is displayed in the **Inspector panel**. Parameters are parsed directly from the chosen FFmpeg binary — meaning custom builds with extra codecs or filters are fully supported.\n\n- Each field corresponds to an FFmpeg flag\n- Tooltips include short descriptions (from FFmpeg’s self-doc system)\n- Numeric, boolean, dropdown, and text fields match expected parameter types\n\nThis makes advanced FFmpeg options accessible without memorizing CLI syntax.",
          "image": "tutorials/nodes-inspector.png"
        },
        {
          "title": "Node Actions",
          "content": "RMB on a node opens its context menu. Common actions:\n- **Description**: Shows FFmpeg documentation for this node\n- **Clone**: Duplicates the node with all current settings\n- **Delete**: Removes the node\n- **Color**: Assigns a custom color for easier grouping\n\nNodes can also be collapsed via the dot in the top-left corner to save space on large graphs.",
          "image": "tutorials/nodes-actions.png"
         
        },
        {
          "title": "Inputs and Outputs",
          "content": "Special nodes define workflow boundaries:\n\n- **Input Node (IN)**: Defines media sources (files, streams, images, etc.)\n- **Output Node (OUT)**: Defines final file path, format, and muxing options\n\nEach workflow must have at least one IN and one OUT node to be valid. Multiple IN/OUT nodes are supported for complex graphs.",
          "image": "tutorials/nodes-in-out.png"
        },
        {
          "title": "Practical Example",
          "content": "Here’s a simple but common pipeline:\n\n1. Add **IN node** → select video file\n2. Add **Scale filter** → set width=1280, height=720\n3. Add **libx264 encoder** → configure bitrate, preset, profile\n4. Add **aac encoder** for audio\n5. Connect both to **OUT node** → set output file path\n\nThe graph now represents a complete transcoding workflow equivalent to a multi-line FFmpeg CLI command — but fully visual and editable.",
          "image": "tutorials/nodes-example.png"
        }
      ],
      "conclusion": "Nodes give you fine-grained control over every part of your pipeline, from filters to codecs. With the inspector, you can configure parameters that normally require deep FFmpeg knowledge — all visually accessible. Next, we’ll look at how to optimize workflows with the Player tab and reusable graph templates."
    },
    {
      "id": "player-and-debugging",
      "title": "Debugging Workflows with the Player",
      "description": "Learn how to use FFStudio’s Player tab to preview and debug your workflows without full renders.",
      "category": "Building Workflows",
      "readTime": "12 min read",
      "date": "September 6, 2025",
      "icon": "fas fa-play-circle",
      "image": "tutorials/player-cover.png",
      "tags": ["player", "preview", "debugging", "workflow"],
      "intro": "Transcoding a full video just to test one filter wastes time. That’s why FFStudio includes the **Player tab** — a lightweight preview system for debugging. You can render just a frame or a short segment, verify results, and adjust your graph until it’s perfect.",
      "sections": [
        {
          "title": "Switching to the Player Tab",
          "content": "Once your graph is complete, click the **Player tab** in the top bar. This switches the workspace from node editing to a preview-focused interface.\n\nThe Player is simple but powerful: it gives you playback controls, a timeline, and the ability to transcode just selected portions of your workflow.",
          "image": "tutorials/player-tab.png"
        },
        {
          "title": "Navigating the Timeline",
          "content": "The timeline lets you choose where to preview:\n- **Click LMB**: Set a playhead position\n- **Click + drag**: Define a range selection\n- **RMB + drag**: Move the timeline viewport\n- **Scroll**: Scroll through timeline\n- **Ctrl + Scroll**: Zoom timeline\n\nYou can reposition or resize a range by dragging its edges, or move the entire selection by dragging the middle.",
          "image": "tutorials/player-timeline.png"
        },
        {
          "title": "Rendering Segments",
          "content": "Instead of transcoding a full workflow, you can render just what’s selected:\n- **Green button (bottom-left)**: Transcode current selection\n  - Single frame if no range\n  - Full segment if a range is selected\n- **Red button**: Reset and clear the selection\n\nThis gives you near-instant feedback to confirm filters, overlays, and encoders are behaving as expected.",
          "image": "tutorials/player-render.png"
        },
        {
          "title": "Managing Segments",
          "content": "Rendered segments appear on the timeline as overlays. Each has its own ✖ icon in the corner for quick removal.\n\nHovering over a segment reveals controls to delete or adjust it. You can preview multiple ranges in one debugging session, helping you validate different parts of the workflow without restarting.",
          "image": "tutorials/player-segments.png"
        },
        {
          "title": "Caching Previews",
          "content": "Once a segment has been rendered, it is cached. Replaying that range does not require re-transcoding, making it faster to recheck your adjustments. When you change the graph significantly, cached segments are invalidated automatically.",
          "image": "tutorials/player-cache.png"
        },
        {
          "title": "Debugging Workflow Issues",
          "content": "The Player is tightly integrated with the **Logs tab**:\n- Any errors during partial rendering immediately highlight the Logs tab in red\n- You can switch back and forth between preview and logs to refine your graph\n\nThis workflow shortens the edit–test–debug loop dramatically, especially for complex pipelines.",
          "image": "tutorials/player-debug.png"
        }
      ],
      "conclusion": "With the Player, you can preview workflows efficiently, testing individual filters or sections without waiting for a full encode. Combined with the Logs tab, this creates a powerful debugging loop. In the next tutorial, we’ll look at advanced topics — like using custom FFmpeg builds to extend FFStudio with your own filters and codecs."
    },
    {
      "id": "custom-ffmpeg-builds",
      "title": "Using Custom FFmpeg Builds",
      "description": "Learn how to connect FFStudio with your own custom-compiled ffmpeg binaries, including extra filters, codecs, or muxers.",
      "category": "Advanced Techniques",
      "readTime": "8 min read",
      "date": "September 6, 2025",
      "icon": "fas fa-cogs",
      "image": "tutorials/custom-ffmpeg-cover.png",
      "tags": ["advanced", "ffmpeg", "custom", "filters", "codecs"],
      "intro": "One of FFStudio’s most powerful features is the ability to work with **any ffmpeg binary you provide**. This is essential for developers and engineers who compile custom builds with experimental filters, hardware acceleration, or proprietary codecs. Instead of locking you into a predefined ffmpeg, FFStudio adapts dynamically to your binary and exposes its full functionality in the node graph.",
      "sections": [         
        {
          "title": "Video tutorial",
          "youtubeVideo": "https://youtu.be/YoIVZdTbBgI"
        },
        {
          "title": "Why Use a Custom Build?",
          "content": "The official ffmpeg releases are powerful, but many production workflows rely on custom builds that include:\n- Hardware-specific acceleration (e.g., CUDA, NVENC, QuickSync)\n- Proprietary or experimental codecs\n- Custom filters or muxers not available in the stock build\n\nFFStudio makes it possible to load these builds directly and use their features in the graph interface."
        }, 
        {
          "title": "Setting the ffmpeg Path",
          "content": "Every workflow in FFStudio has a configurable ffmpeg path:\n- In the **Workflows sidebar**, locate your workflow entry\n- Enter the full path to your custom `ffmpeg` binary\n- Optionally set additional environment variables, such as `LD_LIBRARY_PATH` for shared libraries\n\nThis ensures that all parsing, node generation, and execution are based on *your* binary.",
          "image": "tutorials/custom-ffmpeg-path.png"
        },
        {
          "title": "Automatic Parsing of Features",
          "content": "Once a custom binary is set, FFStudio runs an internal parsing step:\n- Executes `ffmpeg -h full` to extract all supported filters, codecs, and muxers\n- Builds nodes dynamically based on the detected options\n- Populates inspector panels with the correct flags, descriptions, and defaults\n\nThis guarantees that you see the exact capabilities of your build — nothing hidden, nothing missing.",
          "image": "tutorials/custom-ffmpeg-parse.png"
        },
        {
          "title": "Working With Custom Filters",
          "content": "If your build includes extra filters, they will appear in the node search context. You can:\n- Search by filter name (double LMB on empty canvas)\n- Inspect properties exposed from your binary\n- Connect them into your graph just like stock nodes\n\nFFStudio does not distinguish between stock and custom filters — they all work the same.",
          "image": "tutorials/custom-ffmpeg-filters.png"
        },
        {
          "title": "Caching for Faster Reloads",
          "content": "The first time you point FFStudio to a new ffmpeg binary, parsing can take time because of the large amount of configuration data. However, once parsed, the results are cached. Switching to the same binary later will be nearly instant."
        }
      ],
      "conclusion": "By supplying your own ffmpeg builds, you gain full control over your workflow environment. FFStudio adapts to whatever features your binary supports — from cutting-edge filters to proprietary codecs. This makes it an ideal tool for developers, media engineers, and anyone working at the frontier of video processing."
    },
    {
      "id": "best-practices-graphs",
      "title": "Best Practices & Reusable Graphs",
      "description": "Learn how to keep your graphs organized, readable, and reusable across different workflows.",
      "category": "Building Workflows",
      "readTime": "9 min read",
      "date": "September 7, 2025",
      "icon": "fas fa-project-diagram",
      "image": "tutorials/best-practices-cover.png",
      "tags": ["workflow", "organization", "examples", "sharing"],
      "intro": "As workflows grow more complex, managing them effectively becomes critical. FFStudio provides several features to keep your node graphs organized, readable, and reusable. In this tutorial, you’ll learn how to apply best practices for workflow design, and how to take advantage of the built-in example library.",
      "sections": [
        {
          "title": "Organizing Large Graphs",
          "content": "When graphs become crowded, readability suffers. Here are techniques to keep things clean:\n- **Node Groups**: Use grouping or clustering to isolate sections of the workflow (e.g., filters vs encoders)\n- **Colors**: Assign colors to nodes for visual categorization\n- **Collapsed Nodes**: Click the dot at the top-left of a node to collapse it into a compact form when you don’t need to tweak its settings\n\nThese practices make it easier to revisit a workflow later, or to share it with teammates.",
          "image": "tutorials/best-practices-organize.png"
        },
        {
          "title": "Working With the Example Library",
          "content": "FFStudio comes with a large library of ready-to-use graph examples:\n- Browse and drag/drop prebuilt workflows\n- Adapt them by replacing inputs/outputs\n- Learn by studying how they are structured\n\nThis is the fastest way to get started with advanced pipelines without memorizing every ffmpeg flag.",
          "image": "tutorials/best-practices-library.png"
        },
        {
          "title": "Sharing and Exporting Workflows",
          "content": "Every workflow can be exported as JSON. Share them with others or keep them under version control for reproducibility.\n\nTo export:\n- Open the **Workflows sidebar**\n- Click the **Export** button for your workflow\n- Save the JSON file\n\nYour colleagues can import the file to instantly recreate the same graph on their machine.",
          "image": "tutorials/best-practices-export.png"
        }
      ],
      "conclusion": "By applying best practices — grouping, annotating, reusing examples, and exporting workflows — you’ll get the most out of FFStudio. Complex pipelines become manageable, shareable, and easier to maintain. This marks the end of the core tutorial series, but you can now explore advanced graphs and contribute to the example library."
    },
    {
      "id": "basic-transcoding",
      "title": "Basic Transcoding Workflow",
      "description": "Learn how to set up your first simple video transcoding pipeline in FFStudio.",
      "category": "Workflow Examples",
      "readTime": "8 min read",
      "date": "September 7, 2025",
      "icon": "fas fa-exchange-alt",
      "image": "tutorials/basic-transcoding.png",
      "tags": ["beginner", "workflow", "transcoding"],
      "intro": "In this tutorial, we’ll build a minimal video processing workflow: take an input file, select the correct stream, encode it, and save it to MP4. This is the simplest way to understand how FFStudio translates your graph into a working ffmpeg command.",
      "sections": [
        {
          "title": "Step 1: Create a New Workflow",
          "content": "Open FFStudio and click **New Workflow** in the right sidebar. Name your workflow and make sure your default FFmpeg binary is detected. The graph canvas will now activate and you are ready to build.",
          "image": "tutorials/basic-transcoding-step1.png"
        },
        {
          "title": "Step 2: Add Global Options",
          "content": "Right-click on the graph canvas, search for **Global Options**, and add the **-y (overwrite output)** option. This ensures ffmpeg will overwrite old output files automatically. Connect this node to the Input node in the next step.",
          "image": "tutorials/basic-transcoding-step2.png"
        },
        {
          "title": "Step 3: Add an Input Node",
          "content": "Add an **Input** node from the context menu. This represents the media file you want to transcode. In the node’s properties, select your source file. Connect the Global Options node to the Input node.\n\n💡 **Pro Tip:** The Input node has a **Get Media Info** button. Use it to quickly fetch details about your file — stream types, IDs, codecs, and more. This helps you choose the right streams when setting up your Stream Selector.",
          "image": "tutorials/basic-transcoding-step3.png"
        },
        {
          "title": "Step 4: Add a Stream Selector Node",
          "content": "Inputs can contain multiple streams (video, audio, subtitles). Add a **Stream Selector** node and connect the Input to it. In the properties, choose the video stream (Type = video, Id = 0).",
          "image": "tutorials/basic-transcoding-step4.png"
        },
        {
          "title": "Step 5: Add an Encoder Node",
          "content": "Now add a **Video Encoder** node, for example **libx264**. This encoder will later be connected to the Output node to show it is used for the selected stream.",
          "image": "tutorials/basic-transcoding-step5.png"
        },
        {
          "title": "Step 6: Add and Configure the Output Node",
          "content": "Finally, add an **Output** node. This is the hub that ties everything together. Connect the **Stream Selector** to the Output’s **stream slot**, and connect the **Encoder** to the Output’s **enc:v slot**. This makes it clear that this encoder is applied to this output. Set the destination path to an MP4 file.",
          "image": "tutorials/basic-transcoding-step6.png"
        },
        {
          "title": "Step 7: Execute the Graph",
          "content": "Click the green **Execute Graph** button in the sidebar. FFStudio will parse your graph, generate the ffmpeg command, and run it. Progress and messages will appear in the **Logs** tab. Once finished, your transcoded MP4 file will be ready.",
          "image": "tutorials/basic-transcoding-step7.png"
        }
      ],
      "conclusion": "You’ve just completed your first transcoding workflow in FFStudio! This workflow shows the minimal structure: Global Options → Input → Stream Selector → Encoder + Output. From here, you can expand with audio, filters, multiple outputs, or custom options."
    },
    {
      "id": "watermark-overlay",
      "title": "Adding a Watermark to Your Video",
      "description": "Learn how to apply a watermark image using FFStudio’s node-based workflow.",
      "category": "Workflow Examples",
      "readTime": "10 min read",
      "date": "September 7, 2025",
      "icon": "fas fa-image",
      "image": "tutorials/watermark-overlay.png",
      "tags": ["workflow", "filter", "watermark"],
      "intro": "In this tutorial, we’ll build on the basic transcoding workflow by adding a filter: overlaying a watermark image. This shows how FFStudio makes ffmpeg’s powerful filter system intuitive and visual.",
      "sections": [
        {
          "title": "Step 1: Start From a Basic Workflow",
          "content": "If you completed the Basic Transcoding tutorial, you already know the minimal structure: Global Options → Input → Stream Selector → Encoder + Output. We’ll use that as our base.",
          "image": "tutorials/watermark-step1.png"
        },
        {
          "title": "Step 2: Add a Second Input for the Watermark",
          "content": "Right-click on the canvas and add another **Input** node. Select the watermark image file (for example, a PNG with transparency). This will serve as the overlay source.",
          "image": "tutorials/watermark-step2.png"
        },
        {
          "title": "Step 3: Stream Selector for the Watermark",
          "content": "Just like the main video, the watermark input also goes through a **Stream Selector**. Add one, connect it to the watermark Input, and set it to select the video stream of the PNG.",
          "image": "tutorials/watermark-step3.png"
        },
        {
          "title": "Step 4: Add the Overlay Filter",
          "content": "Now add an **Overlay Filter** node. Connect the main video’s Stream Selector to the filter’s first input, and the watermark’s Stream Selector to the filter’s second input. In the properties, set overlay position (e.g., x=10, y=10 for top-left).",
          "image": "tutorials/watermark-step4.png"
        },
        {
          "title": "Step 5: Connect Filter to Stream Selector and Output",
          "content": "Take the output of the Overlay Filter and connect it to a new Stream Selector, and then in the Stream Selector properties, set a unique stream name (e.g., watermarked_v0).\n-    Connect this new Stream Selector to:\n-    The video encoder (enc:v slot) → ensures the filter’s result is encoded.\n-    The Output node’s stream slot (maps) → ensures the filtered stream is included in the final file.\n-    The original video stream redirect to overlay filter in exect order. First video, Second Watermark.\nIf your video also has audio, remember to map the audio stream from the main input’s Stream Selector as well.",
          "image": "tutorials/watermark-step5.png"
        },
        {
          "title": "Step 6: Execute and Verify",
          "content": "Click **Execute Graph**. In the Logs tab you’ll see ffmpeg run the overlay filter. Once finished, open the output video and check that your watermark appears at the correct position.",
          "image": "tutorials/watermark-step6.avif"
        }
      ],
      "conclusion": "You’ve successfully added a watermark overlay using FFStudio! This workflow demonstrates how filters are added as nodes, connected visually, and combined into your transcoding pipeline. From here, you can explore more filters — scaling, cropping, color correction, and more."
    },
    {
      "id": "multi-output-mp4-webm",
      "title": "Exporting to MP4 and WebM in One Pass",
      "description": "Learn how to create a single workflow that produces both an MP4 and a WebM file from the same input video.",
      "category": "Workflow Examples",
      "readTime": "12 min read",
      "date": "September 8, 2025",
      "icon": "fas fa-random",
      "image": "tutorials/multi-output-mp4-webm.png",
      "tags": ["multi-output", "encoding", "mp4", "webm"],
      "intro": "In this tutorial, you'll learn how to set up FFStudio to generate **two different outputs in one run**: an MP4 with H.264 + AAC for universal compatibility, and a WebM with VP9 + Vorbis for open-format delivery. This saves time by avoiding multiple passes over the same input file.",
      "sections": [
        {
          "title": "Step 1: Add the Input Node",
          "content": "Add an **Input** node to the graph and set the source path to your video (e.g., `video.mp4`). This node will feed streams to both outputs.",
          "image": "tutorials/multi-output-step1.png"
        },
        {
          "title": "Step 2: Add Global Options",
          "content": "Add a **Global Options** node with `-y` to allow overwriting existing files. Connect it to the Input node.",
          "image": "tutorials/multi-output-step2.png"
        },
        {
          "title": "Step 3: Select Streams",
          "content": "Create two **Stream Selector** nodes: one for video and one for audio. \n- Set the first to `video`. \n- Set the second to `audio`. \nThis ensures you can route streams cleanly to different encoders and outputs.",
          "image": "tutorials/multi-output-step3.png"
        },
        {
          "title": "Step 4: Add Output Nodes",
          "content": "Create two **Output** nodes — one for the MP4 file and one for the WebM file. Set their destination paths (e.g., `output.mp4` and `output.webm`). These will act as final containers for your encoded streams.",
          "image": "tutorials/multi-output-step4.png"
        },
        {
          "title": "Step 5: Configure the MP4 Output",
          "content": "Add encoders for MP4: \n- **libx264** for video. Set preset to `veryfast` and CRF to `23`. \n- **AAC** for audio. \nConnect both encoders to the MP4 Output node.",
          "image": "tutorials/multi-output-step5.png"
        },
        {
          "title": "Step 6: Configure the WebM Output",
          "content": "Add encoders for WebM: \n- **libvpx-vp9** for video. Add a Video Options node with `-b:v 1M` to target 1 Mbps bitrate. \n- **libvorbis** for audio (for better Windows compatibility). \nConnect both encoders to the WebM Output node.",
          "image": "tutorials/multi-output-step6.png"
        },
        {
          "title": "Step 7: Execute the Graph",
          "content": "Click **Execute Graph** to run. FFStudio will generate both files in a single ffmpeg run, equivalent to the following command:\n\n```bashffmpeg -y -i video.mp4 -map 0:v -map 0:a -c:a aac -c:v libx264 -preset veryfast -crf 23 output.mp4 -map 0:v -map 0:a -b:v 1M -c:a libvorbis -c:v libvpx-vp9 output.webm```",
          "image": "tutorials/multi-output-step7.png"
        }
      ],
      "conclusion": "Congratulations! You've created a workflow that generates multiple outputs from a single input in one pass. This approach is perfect for preparing files for different platforms or formats without redundant re-encoding."
    },
    {
      "id": "multi-bitrate-hls",
      "title": "Exporting Multiple Bitrates in One Pass",
      "description": "Learn how to export the same video into 1080p, 720p, and 480p variants in a single run using FFStudio.",
      "category": "Workflow Examples",
      "readTime": "15 min read",
      "date": "September 8, 2025",
      "icon": "fas fa-layer-group",
      "image": "tutorials/multi-bitrate-export.png",
      "tags": ["multi-bitrate", "encoding", "hls", "adaptive-streaming"],
      "intro": "In this tutorial, you'll create a workflow that outputs the same source video into **three different resolutions (1080p, 720p, and 480p)**. This is useful for adaptive streaming pipelines (e.g., HLS, DASH) or simply preparing multiple qualities for different delivery contexts. Instead of re-encoding the input file three times, you’ll configure FFStudio to generate all variants in one pass.",
      "sections": [
        {
          "title": "Step 1: Add the Input Node",
          "content": "Start with an **Input** node and set the source path to your video file (`video.mp4`). This will feed streams to all outputs.",
          "image": "tutorials/multi-bitrate-step1.png"
        },
        {
          "title": "Step 2: Select Streams",
          "content": "Add two **Stream Selector** nodes:\n- One for **video** streams.\n- One for **audio** streams.\nThese will allow you to branch the same streams to different encoders and filters.",
          "image": "tutorials/multi-bitrate-step2.png"
        },
        {
          "title": "Step 3: Add Scale Filters",
          "content": "For the video selector output, create three **Scale** filter nodes:\n- 1920x1080 → name this output `v1080p`\n- 1280x720 → name this output `v720p`\n- 854x480 → name this output `v480p`\nThese filters downscale the video into different qualities.",
          "image": "tutorials/multi-bitrate-step3.png"
        },
        {
          "title": "Step 4: Re-Select Streams by Name",
          "content": "After scaling, use **Stream Selector** nodes to tag the outputs by name (`v1080p`, `v720p`, `v480p`). This ensures the correct scaled version is mapped into each output container.",
          "image": "tutorials/multi-bitrate-step4.png"
        },
        {
          "title": "Step 5: Add Output Nodes",
          "content": "Create three **Output** nodes:\n- `output_1080p.mp4`\n- `output_720p.mp4`\n- `output_480p.mp4`\nEach will act as a final container for the respective video+audio pair.",
          "image": "tutorials/multi-bitrate-step5.png"
        },
        {
          "title": "Step 6: Configure Encoders",
          "content": "Add encoders and connect them:\n- **Video**: one `libx264` encoder is shared across all three outputs.\n- **Audio**: one `aac` encoder is also shared across outputs.\n- Add **Video Options** nodes to set bitrates per output:\n  - 1080p → `-b:v 5M`\n  - 720p → `-b:v 3M`\n  - 480p → `-b:v 1M`",
          "image": "tutorials/multi-bitrate-step6.png"
        },
        {
          "title": "Step 7: Connect Audio to Outputs",
          "content": "For each output connect the audio. \nThis way each container receives the audio stream.",
          "image": "tutorials/multi-bitrate-step7.png"
        },
        {
          "title": "Step 8: Execute the Graph",
          "content": "Click **Execute Graph**. FFStudio will generate three MP4 files in a single ffmpeg run, equivalent to:\n\n```bash ffmpeg -i video.mp4 -filter_complex '[0:v]scale=w=1920:h=1080[v1080p];[0:v]scale=w=1280:h=720[v720p];[0:v]scale=w=854:h=480[v480p]' -map [v1080p] -map 0:a -b:v 5M -c:a aac -c:v libx264 output_1080p.mp4 -map [v720p] -map 0:a -b:v 3M -c:a aac -c:v libx264 output_720p.mp4 -map [v480p] -map 0:a -b:v 1M -c:a aac -c:v libx264 output_480p.mp4```",
          "image": "tutorials/multi-bitrate-step8.png"
        }
      ],
      "conclusion": "You now have a workflow that generates multiple resolutions in one pass. This method is essential for adaptive streaming workflows, and you can expand it further to generate fragmented MP4 or HLS playlists from the same graph."
    },
    {
      "id": "hls-export",
      "title": "Exporting Multiple Bitrates for HLS Streaming",
      "description": "Learn how to export your video into multiple HLS playlists (1080p, 720p, 480p) in one run using FFStudio.",
      "category": "Workflow Examples",
      "readTime": "15 min read",
      "date": "September 8, 2025",
      "icon": "fas fa-stream",
      "image": "tutorials/multi-bitrate-hls.png",
      "tags": ["hls", "adaptive-streaming", "multi-bitrate", "encoding"],
      "intro": "In this tutorial, you’ll create a workflow that exports the same input video into **HLS adaptive streams** at three different resolutions (1080p, 720p, 480p). This setup generates `.m3u8` playlists with segmented `.ts` files, making the content ready for adaptive delivery across devices.",
      "sections": [
        {
          "title": "Step 1: Add the Input Node",
          "content": "Start by adding an **Input** node to the canvas and setting its path to your source video (`video.mp4`). This will serve as the stream source for all HLS outputs.",
          "image": "tutorials/hls-step1.png"
        },
        {
          "title": "Step 2: Select Streams",
          "content": "Use two **Stream Selector** nodes:\n- One for **video** streams.\n- One for **audio** streams.\nThis allows you to branch both streams to different filters and encoders as needed.",
          "image": "tutorials/hls-step2.png"
        },
        {
          "title": "Step 3: Add Bitrate Controls",
          "content": "Attach **Video Options (-b)** nodes to define target bitrates:\n- 1080p → `-b:v 5M`\n- 720p → `-b:v 3M`\n- 480p → `-b:v 1M`\n\nTo make sure the bitrate applies to the correct type (video or audio), connect the bitrate node to an existing or new **Stream Selector** set to the right type. This ensures, for example, that `-b:v` applies only to video streams.",
          "image": "tutorials/hls-step3.png"
        },
        {
          "title": "Step 4: Add Scale Filters",
          "content": "Add **Scale** filter nodes to the video branch to generate different sizes:\n- `1920x1080`\n- `1280x720`\n- `854x480`\n\nThese filters downscale the video into multiple qualities for HLS delivery. Remember: **Global Option nodes are chainable**, so you can link multiple global settings together (e.g., scaling, bitrates, presets) in sequence without conflict.",
          "image": "tutorials/hls-step4.png"
        },
        {
          "title": "Step 5: Add HLS Muxer",
          "content": "Drag in an **HLS Muxer** node and set the playlist type to `vod`. This tells FFmpeg to produce a VOD-style `.m3u8` playlist with segments that can be streamed or hosted on a server.",
          "image": "tutorials/hls-step5.png"
        },
        {
          "title": "Step 6: Add Output Nodes",
          "content": "Create three **Output** nodes, one for each quality:\n- `output_1080p.m3u8`\n- `output_720p.m3u8`\n- `output_480p.m3u8`\nAttach the correct bitrate and scale to each output. Also connect them to the HLS muxer.",
          "image": "tutorials/hls-step6.png"
        },
        {
          "title": "Step 7: Execute the Graph",
          "content": "Click **Execute Graph**. FFStudio will generate `.m3u8` playlists and `.ts` segments in a single ffmpeg run. The equivalent command is:\n\n```bash ffmpeg -y -i video.mp4 -map 0:a -map 0:v -f hls -hls_time 6 -hls_playlist_type vod -b:v 5M -s 1920x1080 output_1080p.m3u8 -map 0:a -map 0:v -f hls -hls_time 6 -hls_playlist_type vod -b:v 3M -s 1280x720 output_720p.m3u8 -map 0:a -map 0:v -f hls -hls_time 6 -hls_playlist_type vod -b:v 1M -s 854x480 output_480p.m3u8```",
          "image": "tutorials/hls-step7.png"
        }
      ],
      "conclusion": "You now have a workflow that outputs multiple `.m3u8` playlists for adaptive HLS streaming. This is the foundation for scalable streaming systems, and you can expand it further with master playlists that reference these variant streams."
    },
    {
      "id": "hls-master-manifest",
      "title": "Exporting HLS with Master Playlist",
      "description": "Learn how to export multiple resolutions into an adaptive HLS output with a master playlist that references all variants.",
      "category": "Workflow Examples",
      "readTime": "20 min read",
      "date": "September 13, 2025",
      "icon": "fas fa-stream",
      "image": "tutorials/multi-bitrate-hls.png",
      "tags": ["hls", "adaptive-streaming", "multi-bitrate", "manifest"],
      "intro": "In this tutorial, you’ll extend the multi-bitrate export workflow by creating an **HLS package** with multiple variants (1080p, 720p, 480p). Instead of separate MP4 files, you’ll produce `.m3u8` playlists for each resolution plus a **master manifest** that ties them together. This setup is the foundation of adaptive HTTP Live Streaming (HLS).",
      "sections": [
        {
          "title": "Step 1: Add the Input Node",
          "content": "Start with an **Input** node pointing to your source video (video.mp4). This will provide both video and audio streams for the HLS workflow.",
          "image": "tutorials/hls-masater-step1.png"
        },
        {
          "title": "Step 2: Separate Video and Audio",
          "content": "Use two **Stream Selector** nodes:\n- One for **video** (all video streams).\n- One for **audio** (select the primary audio track).\nThis lets you scale video streams independently while keeping audio consistent across renditions.",
          "image": "tutorials/hls-masater-step2.png"
        },
        {
          "title": "Step 3: Split Video Streams",
          "content": "Add a **Split** node to branch the video stream into three paths (for 1080p, 720p, and 480p). Each path will be scaled differently.",
          "image": "tutorials/hls-masater-step3.png"
        },
        {
          "title": "Step 4: Apply Scaling Filters",
          "content": "Attach **Scale** filters to each branch:\n- 1920x1080 → name this output v1080p\n- 1280x720 → name this output v720p\n- 854x480 → name this output v480p\n\nThis ensures each variant has the correct resolution.",
          "image": "tutorials/hls-masater-step4.png"
        },
        {
          "title": "Step 5: Re-Select Streams by Name",
          "content": "After scaling, use **Stream Selector** nodes to tag each video stream (`v1080p`, `v720p`, `v480p`). These named streams will be mapped into the final HLS muxer.",
          "image": "tutorials/hls-masater-step5.png"
        },
        {
          "title": "Step 6: Configure Video/Audio Bitrates",
          "content": "Attach **Video Options (-b:v)** nodes to each video stream:\n- 1080p → 5M\n- 720p → 3M\n- 480p → 1M\n- a → 128k\n\nThis defines the target bitrate for each resolution in the adaptive ladder.\n\nChain Global/Per-file option nodes. These are chainable — you can add multiple and link them together in sequence. This is where you fine-tune encoder constraints for HLS compatibility.",
          "image": "tutorials/hls-masater-step6.png"
        },
        {
          "title": "Step 7: Add the HLS Muxer",
          "content": "Insert an **HLS Muxer** node and configure it:\n- Output segment pattern: `stream_%v_%03d.ts`\n- Variant playlists: `stream_%v.m3u8`\n- Master playlist: `master.m3u8`\n- Playlist type: VOD (Video on Demand)\n\nThe `%v` placeholder will be replaced by the variant index (0,1,2).",
          "image": "tutorials/hls-masater-step7.png"
        },
        {
          "title": "Step 8: Add the Output Node",
          "content": "Finally, connect everything into an **Output** node pointing to your HLS output folder (e.g., `output/hls_output/`). This will generate the `.ts` segments, variant `.m3u8` playlists, and the master manifest.",
          "image": "tutorials/hls-masater-step8.png"
        },
        {
          "title": "Step 9: Execute the Graph",
          "content": "Click **Execute Graph**. FFStudio will generate adaptive HLS output equivalent to running:\n\n```bash C:\\ffmpegs\\ffmpeg-6.1\\ffmpeg.exe -i C:\\sources\\video.mp4 -filter_complex \"[0:v]split=outputs=3[v0][v1][v2];[v0]scale=width=1920:height=1080[v1080p];[v1]scale=width=1280:height=720[v720p];[v2]scale=width=854:height=480[v480p]\" -map [v1080p] -map [v720p] -map [v480p] -map 0:a:0 -map 0:a:0 -map 0:a:0 -f hls -hls_segment_filename C:\\sources\\output\\hls_output\\stream_%v_%03d.ts -hls_playlist_type vod -var_stream_map \"v:0,a:0 v:1,a:1 v:2,a:2\" -master_pl_name master.m3u8 -b:v:0 5M -b:v:1 3M -b:v:2 1M -b:a 128k C:\\sources\\output\\hls_output\\stream_%v.m3u8```",
          "image": "tutorials/hls-masater-step9.png"
        }
      ],
      "conclusion": "You now have a workflow that generates an adaptive HLS output with a **master playlist**. Video players will automatically select the appropriate stream based on network conditions. This approach is production-ready and can be extended with more renditions, DRM, or live streaming settings."
    },
    {
      "id": "dash-export",
      "title": "Exporting Video for MPEG-DASH Streaming",
      "description": "Learn how to set up a graph in FFStudio that exports a video into an MPEG-DASH package with multiple bitrates and segments.",
      "category": "Workflow Examples",
      "readTime": "15 min read",
      "date": "September 9, 2025",
      "icon": "fas fa-network-wired",
      "image": "tutorials/dash-export.png",
      "tags": ["dash", "adaptive-streaming", "encoding", "segments"],
      "intro": "MPEG-DASH is a widely used standard for adaptive streaming. In this tutorial, we’ll use **FFStudio** to create a workflow that outputs a video packaged into DASH with multiple variants and properly segmented `.m4s` chunks. You’ll also learn how to configure segment paths to avoid permission issues.",
      "sections": [
        {
          "title": "Step 1: Add the Input Node",
          "content": "Create an **Input** node and set the source path to your video (e.g., `video.mp4`, and don't forget -y node!). This node feeds both video and audio streams into the workflow.\n\n💡 Use the **Get Media Info** button if you’re unsure which streams are available (video, audio, IDs).",
          "image": "tutorials/dash-step1.png"
        },
        {
          "title": "Step 2: Select Streams",
          "content": "Add **Stream Selector** nodes to separate video and audio streams. Typically:\n- One selector for **video**\n- One selector for **audio**\n\nThis lets you branch them out to encoders and filters independently.",
          "image": "tutorials/dash-step2.png"
        },
        {
          "title": "Step 3: Configure Video Variants",
          "content": "Add **video option nodes** for bitrate (`-b:v`) and scaling (`-s`) to define multiple qualities, such as:\n- 1080p → `1920x1080` at `5M`\n- 720p → `1280x720` at `3M`\n- 480p → `854x480` at `1M`\n\n⚡ To specify whether options apply to video or audio, connect them to a **Stream Selector** with the correct type.",
          "image": "tutorials/dash-step3.png"
        },
        {
          "title": "Step 4: Add Global and Advanced Options",
          "content": "Chain **Global/Per-file option nodes** like `-profile:v main` or `-level 3.1`. These are **chainable** — you can add multiple and link them together in sequence. This is where you fine-tune encoder constraints for DASH compatibility.",
          "image": "tutorials/dash-step4.png"
        },
        {
          "title": "Step 5: Add Encoders",
          "content": "Connect encoders to your streams:\n- **Video**: `libx264` (or another DASH-compatible encoder)\n- **Audio**: `aac`\n\nMake sure both are linked to the output node.",
          "image": "tutorials/dash-step5.png"
        },
        {
          "title": "Step 6: Configure the DASH Muxer",
          "content": "Add the **DASH Muxer** node. This defines how `.mpd` manifests and `.m4s` chunks are written.\n\n👉 Important: set the **segment path** (e.g., `C:\\ffmpegs\\segments\\chunk-stream$RepresentationID$-$Number%05d$.m4s`). Without it, ffmpeg may fail if it can’t write into the current directory.",
          "image": "tutorials/dash-step6.png"
        },
        {
          "title": "Step 7: Create the Output Node",
          "content": "Add an **Output** node and set the path to the `.mpd` file (e.g., `C:\\ffmpegs\\output.mpd`).\n\nConnect the following:\n- Video encoder\n- Audio encoder\n- DASH muxer\n- All relevant stream selectors",
          "image": "tutorials/dash-step7.png"
        },
        {
          "title": "Step 8: Execute the Graph",
          "content": "Click **Execute Graph**. FFStudio will run a command similar to:\n\n```bash C:\\ffmpegs\\ffmpeg-5.1\\ffmpeg.exe -y -i C:\\ffmpegs\\video.mp4 -map 0:v:0 -map 0:v:0 -map 0:v:0 -map 0:a -f dash -seg_duration 6 -use_template 1 -use_timeline 1 -media_seg_name \"C:\\ffmpegs\\segments\\chunk-stream$RepresentationID$-$Number%05d$.m4s\" -b:v:0 5M -s:v:0 1920x1080 -profile:v:0 main -b:v:1 3M -s:v:1 1280x720 -profile:v:1 main -b:v:2 1M -s:v:2 854x480 -profile:v:2 baseline -c:a aac -c:v libx264 -level 3.1 -crf 23 C:\\ffmpegs\\output.mpd ```",
          "image": "tutorials/dash-step8.png"
        }
      ],
      "conclusion": "Your workflow now exports a DASH-compliant stream with multiple qualities. The `.mpd` manifest and `.m4s` segments can be served directly via any HTTP server. From here, you can extend the graph to add more qualities or enable encryption (Widevine, FairPlay, etc.)."
    },
    {
      "id": "quick-gif-conversion",
      "title": "Quick & Simple GIF Conversion",
      "description": "Learn how to quickly convert videos to GIF format with basic quality adjustments.",
      "category": "Workflow Examples",
      "readTime": "8 min read",
      "date": "September 10, 2025",
      "icon": "fas fa-bolt",
      "image": "tutorials/gif-conversion.png",
      "tags": ["gif", "conversion", "quick", "simple"],
      "intro": "In this tutorial, you'll learn how to create a simple workflow for converting video files to GIF format. This approach is perfect for quick conversions where file size isn't a primary concern.",
      "sections": [
        {
          "title": "Step 1: Add the Input Node",
          "content": "Add an **Input** node to the graph and set the source path to your video file (e.g., `video.mp4`).",
          "image": "tutorials/gif-quick-step1.png"
        },
        {
          "title": "Step 2: Add Global Options",
          "content": "Add a **Global Options** node with `-y` to allow overwriting existing files. Connect it to the Input node.",
          "image": "tutorials/gif-quick-step2.png"
        },
        {
          "title": "Step 3: Select Video Stream",
          "content": "Create a **Stream Selector** node set to `video` to isolate the video stream from your input.",
          "image": "tutorials/gif-quick-step3.png"
        },
        {
          "title": "Step 4: Adjust Frame Rate (Optional)",
          "content": "Add an **FPS Filter** node to reduce the frame rate if needed. For GIFs, 10-15 FPS is often sufficient and reduces file size.",
          "image": "tutorials/gif-quick-step4.png"
        },
        {
          "title": "Step 5: Resize Video (Optional)",
          "content": "Add a **Scale Filter** node to reduce dimensions if needed. Smaller dimensions significantly reduce GIF file size.",
          "image": "tutorials/gif-quick-step5.png"
        },
        {
          "title": "Step 6: Add Output Node",
          "content": "Create an **Output** node and set the destination to your GIF file (e.g., `output.gif`). Connect your processed video stream to this node.",
          "image": "tutorials/gif-quick-step6.png"
        },
        {
          "title": "Step 7: Execute the Graph",
          "content": "Click **Execute Graph** to convert your video to GIF. The equivalent command is:\n\n```bash C:\\ffmpegs\\ffmpeg-4.2\\ffmpeg.exe -y -i C:\\sources\\5sec.mp4 -filter_complex \"[0:v]fps=fps=10[vfps];[vfps]scale=w=480:h=-1[vscale]\" -map [vscale] C:\\sources\\output.gif```",
          "image": "tutorials/gif-quick-step7.png"
        }
      ],
      "conclusion": "You've created a simple workflow for converting videos to GIF format. While this approach is quick, the resulting GIFs may be large in file size and have limited colors. For higher quality results with smaller file sizes, see our Best Practices tutorial."
    },
    {
      "id": "high-quality-gif",
      "title": "High-Quality GIF Conversion with Palette Optimization",
      "description": "Learn how to create optimized GIFs with better quality and smaller file sizes using palette generation.",
      "category": "Workflow Examples",
      "readTime": "12 min read",
      "date": "September 10, 2025",
      "icon": "fas fa-palette",
      "image": "tutorials/gif-conversion.png",
      "tags": ["gif", "palette", "optimization", "quality"],
      "intro": "In this tutorial, you'll learn how to create high-quality GIFs with optimized file sizes using FFmpeg's palettegen and paletteuse filters. This method generates a custom color palette for your video, resulting in better visual quality and smaller file sizes compared to basic conversion methods.",
      "sections": [
        {
          "title": "Step 1: Add the Input Node",
          "content": "Add an **Input** node to the graph and set the source path to your video file (e.g., `video.mp4`).",
          "image": "tutorials/gif-quality-step1.png"
        },
        {
          "title": "Step 2: Add Global Options",
          "content": "Add a **Global Options** node with `-y` to allow overwriting existing files. Connect it to the Input node.",
          "image": "tutorials/gif-quality-step2.png"
        },
        {
          "title": "Step 3: Select Video Stream",
          "content": "Create a **Stream Selector** node set to `video` to isolate the video stream from your input.",
          "image": "tutorials/gif-quality-step3.png"
        },
        {
          "title": "Step 4: Adjust Frame Rate and Scale",
          "content": "Add an **FPS Filter** node to set an appropriate frame rate (10-15 FPS works well for GIFs). Then add a **Scale Filter** node to resize your video to appropriate dimensions.",
          "image": "tutorials/gif-quality-step4.png"
        },
        {
          "title": "Step 5: Split the Video Stream",
          "content": "Add a **Split Filter** node to create two identical streams from your processed video. One stream will be used for palette generation, and the other for the final output.",
          "image": "tutorials/gif-quality-step5.png"
        },
        {
          "title": "Step 6: Generate Color Palette",
          "content": "Add a **Palettegen Filter** node to one branch of the split stream. This will analyze the video and generate an optimized color palette.",
          "image": "tutorials/gif-quality-step6.png"
        },
        {
          "title": "Step 7: Apply Palette to Video",
          "content": "Add a **Paletteuse Filter** node. Connect the other branch of your split video stream to the first input, and the palette stream to the second input.",
          "image": "tutorials/gif-quality-step7.png"
        },
        {
          "title": "Step 8: Add Output Node",
          "content": "Create an **Output** node and set the destination to your GIF file (e.g., `output.gif`). Connect the output from the Paletteuse filter to this node.",
          "image": "tutorials/gif-quality-step8.png"
        },
        {
          "title": "Step 9: Execute the Graph",
          "content": "Click **Execute Graph** to convert your video to an optimized GIF. The equivalent command is:\n\n```bash C:\ffmpegs\ffmpeg-4.2\ffmpeg.exe -y -i C:\\sources\\5sec.mp4 -filter_complex \"[0:v]fps=fps=15[vfps];[vfps]scale=w=480:h=-1[vscale];[vscale]split=outputs=2[a][b];[a]palettegen=stats_mode=diff[p];[b][p]paletteuse=diff_mode=rectangle[result]\" -map [result] C:\\sources\\output.gif```",
          "image": "tutorials/gif-quality-step9.png"
        }
      ],
      "conclusion": "Congratulations! You've created a workflow that generates high-quality GIFs with optimized file sizes using palette generation. This method produces significantly better results than simple conversion, with more accurate colors and smaller file sizes."
    },
    {
      "id": "whisper-transcription",
      "title": "Automated Audio Transcription with OpenAI Whisper",
      "description": "Learn how to transcribe audio or extract subtitles from any video file LOCALLY using the power of OpenAI's Whisper model directly inside an FFmpeg graph.",
      "category": "Workflow Examples",
      "readTime": "10 min read",
      "date": "September 12, 2025",
      "icon": "fas fa-language",
      "image": "tutorials/whisper-transcription.png",
      "tags": ["whisper", "ai", "transcription", "subtitles", "audio"],
      "intro": "In this tutorial, you'll build a graph that takes any video or audio file, extracts the audio track, and sends it to OpenAI's state-of-the-art Whisper model for transcription. The result will be a text file (or subtitle file) with the spoken content, all in a single, automated workflow. ⚠️ Important: This requires a special FFmpeg build with Whisper support and a pre-downloaded Whisper model file.",
      "sections": [
        {
          "title": "Prerequisite: Get FFmpeg with Whisper Support",
          "content": "The whisper filter requires a recent FFmpeg build that includes this functionality. You can download the official FFmpeg build with Whisper support directly from the FFmpeg website.",
          "image": "tutorials/whisper-prerequisite.png"
        },
        {
          "title": "Prerequisite: Get Whisper Model",
          "content": "Download a compatible Model from whisper.cpp repositories or other sources providing nightly/essentials builds",
          "image": "tutorials/whisper-prerequisite1.png"
        },
        {
          "title": "Step 1: Add the Input Node",
          "content": "Add an **Input** node to the graph and set the source path to your video file (e.g., `podcast.mp4`). This node will provide the audio stream for Whisper to process.",
          "image": "tutorials/whisper-step1.png"
        },
        {
          "title": "Step 2: Add Global Options",
          "content": "Add a **Global Options** node with `-y` to allow overwriting existing files. Connect it to the Input node.",
          "image": "tutorials/whisper-step2.png"
        },
        {
          "title": "Step 3: Select the Audio Stream",
          "content": "Create a **Stream Selector** node and set it to `audio` to isolate the audio stream from your input. Whisper only needs the audio track to work.",
          "image": "tutorials/whisper-step3.png"
        },
        {
          "title": "Step 4: Configure the Whisper Filter Node",
          "content": "Add a **Whisper Filter** node and connect the audio stream to it. Configure these crucial settings:\n- **Model:** Path to your Whisper model file (must be a .bin file from whisper.cpp project, available on HuggingFace)\n- **Language:** Set the spoken language (e.g., `en` for English)\n- **Output Format:** Choose your output format: `txt` for plain text, `json` for JSON with timestamps, or `srt` for subtitles\n- **Output File:** Set the path for the resulting text file (e.g., `transcript.srt`)",
          "image": "tutorials/whisper-step4.png"
        },
        {
          "title": "Step 5: Configure the Output",
          "content": "Since we're generating a text file, not a media file:\n1. Add a **Null Muxer** node to avoid creating unnecessary media output\n2. Add a **`-vn` (Video Options)** node to disable video processing\nConnect both to your Output node and set its path to `-` to output to stdout",
          "image": "tutorials/whisper-step5.png"
        },
        {
          "title": "Step 6: Execute the Graph",
          "content": "Click **Execute Graph** to run. FFmpeg will extract the audio, pipe it to the Whisper filter, and generate your transcript file. The console will show Whisper's progress. The equivalent command is:\n\n```bash C:\\ffmpeg\\bin\\ffmpeg.exe -y  -i C:\\sources\\podcast.mp4 -filter_complex \"[0:a:0]whisper=model=C\\\\:/sources/ggml-large-v3.bin:language=en:destination=C\\\\:/sources/result.json:format=json\"  -f null -vn  -```",
          "image": "tutorials/whisper-step6.png"
        }
      ],
      "conclusion": "You've successfully created an automated transcription pipeline! This graph can be reused for any video or audio file. Experiment with different Whisper models (e.g., 'base', 'small', 'medium') for a balance of speed and accuracy, or change the output format to get exactly the transcription style you need."
    },
    {
      "id": "windows-filter-paths",
      "title": "Windows Filter Path Format: <code>The C\\\\:/path/to/file</code> Syntax",
      "description": "Learn the specific path format required for FFmpeg filters on Windows and why the colon character must be escaped with a backslash.",
      "category": "Getting Started",
      "readTime": "6 min read",
      "date": "September 12, 2025", 
      "icon": "fas fa-file-alt",
      "image": "tutorials/windows-filter-paths.png",
      "tags": ["windows", "paths", "filters", "colon", "escaping"],
      "intro": "When working with FFmpeg filters on Windows, you must use a specific path format that differs from standard Windows paths. This tutorial explains why filters require <code>C\\\\:/path/to/file.bin</code> syntax and how to properly escape the colon character in filter parameters.",
      "sections": [
        {
          "title": "Why Filters Need Special Path Formatting",
          "content": "FFmpeg filters parse their parameters differently than main input/output arguments. The colon (:) character has special meaning in filter syntax as it separates parameter names from values. This means standard Windows paths like <code>C:/path/to/file.bin</code> will be misinterpreted because the colon is treated as a syntax separator rather than part of the path.",
          "image": "tutorials/filter-parsing.png"
        },
        {
          "title": "The Required Format: Escape the Colon",
          "content": "For filters on Windows, you must escape the colon character with a backslash. The correct format is:\n\n<code>C\\\\:/path/to/your/file.bin</code>\n\nNote the backslash before the colon. This tells FFmpeg's filter parser to treat the colon as a literal character rather than a parameter separator.",
          "image": "tutorials/escaped-colon.png"
        },
        {
          "title": "Comparison: What Works vs. What Doesn't",
          "content": "Here's how different path formats behave in Windows filters:\n\n✅ <strong>Works:</strong> <code>C\\\\:/sources/ggml-large-v3.bin</code>\n✅ <strong>Works:</strong> <code>relative/path/to/file.bin</code>\n❌ <strong>Fails:</strong> <code>C:/sources/ggml-large-v3.bin</code>\n❌ <strong>Fails:</strong> <code>C\\\\:\\\\sources\\\\ggml-large-v3.bin</code>\n\nOnly the escaped colon format is guaranteed to work in filter parameters."
        },
        {
          "title": "Step-by-Step: Formatting Filter Paths",
          "content": "Follow this process when adding paths to filter parameters:\n\n1. Start with your normal Windows path: <code>C:\\sources\\model.bin</code>\n2. Identify the colon character after the drive letter\n3. Insert a backslash before the colon: <code>C\\\\:\\sources\\model.bin</code>\n4. Use forward slashes for the rest of the path <code>C\\\\:/sources/model.bin</code>\n5. Paste this formatted path into your filter parameter",
          "image": "tutorials/formatting-steps.png"
        },
        {
          "title": "Real-World Examples",
          "content": "Here's how this applies to common filters:\n\n<strong>Whisper Filter:</strong>\n<code>whisper=model=C\\\\:/models/ggml-base.en.bin:language=en</code>\n\n<strong>Subtitles Filter:</strong> \n<code>subtitles=filename=C\\\\:/assets/subtitles.srt</code>\n\n<strong>LUT Filter:</strong>\n<code>lut3d=file=C\\\\:/luts/custom.cube</code>\n\nNote how the colon after the drive letter is escaped, but the colons in filter parameters are not.",
          "image": "tutorials/real-examples.png"
        },
        {
          "title": "Troubleshooting Path Errors",
          "content": "If your filter isn't working, check these common issues:\n\n1. <strong>Missing backslash before colon:</strong> <code>C:/path</code> instead of <code>C\\\\:/path</code>\n2. <strong>Incorrect slash direction:</strong> Use <code>C\\\\:/path/to/file</code> not <code>C\\\\:\\path\\to\\file</code>\n3. <strong>File doesn't exist:</strong> Verify the path is correct after formatting\n4. <strong>Permission issues:</strong> Ensure FFmpeg can access the file location\n\nCheck the FFmpeg console output for specific error messages about file access.",
          "image": "tutorials/troubleshooting-paths.png"
        }
      ],
      "conclusion": "Windows filter paths require specific formatting: escape the colon character with a backslash (<code>C\\\\:/path/to/file</code>) and use forward slashes for the remainder of the path. This syntax ensures FFmpeg's filter parser correctly interprets Windows paths without confusing the colon with parameter separators. Remember this rule whenever working with file-based filters on Windows systems."
    },
    {
      "id": "stitch-videos-looping-audio",
      "title": "Stitch Videos with Different Formats and Add Looping Audio",
      "description": "Learn how to combine videos with different formats, resolutions, and frame rates into a seamless sequence with continuous looping background audio.",
      "category": "Workflow Examples",
      "readTime": "25 min read",
      "date": "September 16, 2025",
      "icon": "fas fa-film",
      "image": "tutorials/stitch-videos-audio.png",
      "tags": ["concatenate", "looping audio", "video stitching", "normalization", "fade effects"],
      "intro": "In this tutorial, you'll learn how to combine three different videos (with varying formats, resolutions, and frame rates) into a single seamless video. You'll also add background audio that loops continuously throughout the entire sequence, with smooth fade transitions between videos.",
      "sections": [
        {
          "title": "Step 1: Understanding the Workflow",
          "content": "This workflow processes three different video sources (A.mp4, B.mov, and C.webm) with potentially different properties, and combines them with a background audio track (E.flac) that loops continuously.\n **Each video is:**\n- Scaled to a consistent resolution (1920x1080)\n- Faded in at the beginning\n- Faded out at the end\n- Concatenated into a single sequence\n\n**The audio is processed with:**\n- A fade in at the beginning\n- A fade out at the end\n- Looping to continue throughout the entire video\n- Mixed with the final video output",
          "image": "tutorials/stitch-overview.png"
        },
        {
          "title": "Step 2: Add Input Nodes",
          "content": "Add four **Input** nodes:\n- Three for your video sources (A.mp4, B.mov, C.webm)\n- One for your audio source (E.flac)\n\nThese will serve as the starting points for all processing. Even though the videos have different formats and properties, FFStudio will handle the decoding automatically.",
          "image": "tutorials/stitch-inputs.png"
        },
        {
          "title": "Step 3: Process Each Video (Timing Considerations)",
          "content": "For each video, follow these steps:\n\n1. Add a **Stream Selector** node to extract the video stream\n2. Add a **Scale** filter node to normalize the resolution to 1920x1080\n3. Add a **Fade In** filter node (typically 1-2 seconds for a smooth opening)\n4. Add a **Fade Out** filter node (crucial for seamless transitions)\n\n**Important Timing Consideration:**\nFor fade out effects, you need to know the exact duration of each video segment to position the fade correctly. The fade out should start a few seconds before the end of each clip. You can:\n- Check each video's duration in the media info panel\n- Calculate the fade start time as (total duration - fade length)\n- Set the fade duration based on your desired transition smoothness (typically 1-3 seconds)\n\nUse **Stream Selector** nodes to name the outputs (v0_scale, v0_fade_in, v0_fade_out) for easy reference later.",
          "image": "tutorials/stitch-video-processing.png"
        },
        {
          "title": "Step 4: Process the Audio",
          "content": "For the audio track:\n\n1. Add a **Stream Selector** node to extract the audio stream\n2. Add an **Audio Fade In** filter node (set to 1-2 seconds)\n3. Add an **Audio Fade Out** filter node (set to match the video fade out timing)\n4. Add an **Audio Loop** filter node (set to loop multiple times with sufficient buffer size)\n5. Use **Stream Selector** nodes to name the outputs (a0_fade_in, a0_fade_out)",
          "image": "tutorials/stitch-audio-processing.png"
        },
        {
          "title": "Step 5: Concatenate the Videos",
          "content": "Add a **Concat** filter node with 3 inputs. Connect the faded outputs from all three videos (v0_fade_out, v1_fade_out, v2_fade_out) to the concat node. This will combine them into a single video stream in sequence.",
          "image": "tutorials/stitch-concat.png"
        },
        {
          "title": "Step 6: Configure Output",
          "content": "Add an **Output** node and configure it:\n\n1. Connect the concatenated video stream\n2. Connect the processed audio stream\n3. Set the output path (e.g., result.mp4)\n4. Add the **-shortest** option to ensure the output ends when the video ends\n5. Add the **-y** option to overwrite output files without prompting",
          "image": "tutorials/stitch-output.png"
        },
        {
          "title": "Step 7: Execute the Graph",
          "content": "Click **Execute Graph**. FFStudio will process all videos, normalize them to the same specifications, apply fade effects, concatenate them, and add the looping audio track with proper fading.\n\nThe equivalent ffmpeg command would be complex due to the multiple filters and processing steps, but FFStudio simplifies this through a visual interface.",
          "image": "tutorials/stitch-execute.png"
        }
      ],
      "conclusion": "You've successfully created a workflow to combine multiple videos with different properties into a single cohesive video with continuously looping background audio. This technique is useful for creating compilations, highlight reels, or any project where you need to merge disparate video sources while maintaining professional transitions and continuous audio."
    },
    {
      "id": "vertical-to-horizontal-conversion",
      "title": "Transforming Vertical Video to Horizontal Format with Blur Effects",
      "description": "Learn how to convert vertical video sources into horizontal format using blur effects to fill empty areas naturally.",
      "category": "Workflow Examples",
      "readTime": "15 min read",
      "date": "September 17, 2025",
      "icon": "fas fa-arrows-alt-h",
      "image": "tutorials/vertical-to-horizontal.png",
      "tags": ["aspect-ratio", "vertical-video", "blur-effects", "video-processing"],
      "intro": "In this tutorial, you'll learn how to transform vertical (9:16) video content into horizontal (16:9) format using FFStudio's node-based workflow. This technique solves the common problem of black bars on the sides by creating aesthetically pleasing blur effects that extend the background naturally.",
      "sections": [
        {
          "title": "Step 1: Set Up Input and Global Options",
          "content": "Start by adding an **Input Node** configured with your vertical source video path (e.g., `C:\\sources\\vert_video_sample.mp4`). Connect a **Global Options Node** with the `-y` flag to enable overwrite confirmation for the output file.",
          "image": "tutorials/vert-hor-step1.png"
        },
        {
          "title": "Step 2: Separate Video Stream",
          "content": "Add a **Stream Selector Node** configured to select by type: **video**. This isolates the video stream from potential audio tracks for processing.",
          "image": "tutorials/vert-hor-step2.png"
        },
        {
          "title": "Step 3: Create Parallel Processing Paths",
          "content": "Branch the video stream into two paths using two **Stream Selector Nodes**. Both will receive the same video stream but will be processed differently:\n- Path 1: Main content processing\n- Path 2: Background effect processing"
        },
        {
          "title": "Step 4: Process Main Content Path",
          "content": "On the first path:\n- Add a **Crop Filter** with `out_w=\"ih*9/16\"` to maintain vertical aspect ratio\n- Name output: `v0_crop`\n- Add a **Scale Filter** with `w=\"-1\"`, `h=\"ih*1.2\"` to slightly enlarge content\n- Name output: `v0_scale`",
          "image": "tutorials/vert-hor-step4.png"
        },
        {
          "title": "Step 5: Process Background Effect Path",
          "content": "On the second path:\n- Add a **Scale Filter** with `w=\"ih*16/9\"`, `h=\"-1\"` to convert to horizontal aspect ratio\n- Name output: `v1_scaled`\n- Add a **Gaussian Blur Filter** with sigma value: `30`\n- Name output: `v1_blur`\n- Add a **Crop Filter** with `out_h=\"iw*9/16\"` to refine the blurred background\n- Name output: `v1_crop`",
          "image": "tutorials/vert-hor-step5.png"
        },
        {
          "title": "Step 6: Overlay and Composite Streams",
          "content": "Combine processed streams using an **Overlay Filter Node**:\n- Connect main content stream (`v0_scale`) to overlay input\n- Connect background stream (`v1_crop`) to base input\n- Configure position: `x=\"(main_w-overlay_w)/2\"` to center content\n- Name output: `v_overlay`",
          "image": "tutorials/vert-hor-step6.png"
        },
        {
          "title": "Step 7: Final Scaling and Output",
          "content": "Prepare the final output:\n- Add a **Scale Filter** with `w=\"1920\"`, `h=\"1080\"` for Full HD output\n- Name output: `v_result`\n- Add an **Output Node** with destination path (e.g., `C:\\sources\\output\\hor_video.mp4`)",
          "image": "tutorials/vert-hor-step7.png"
        },
        {
          "title": "Step 8: Execute the Graph",
          "content": "Review all connections and click **Execute Graph**. FFStudio will process the vertical video into horizontal format with blur effects, equivalent to running:\n\n```bash C:\\ffmpegs\\ffmpeg-3.2\\ffmpeg.exe -y -i C:\\sources\\vert_video_sample.mp4 -filter_complex \"[0:v]crop=out_w=ih*9/16[v0_crop];[0:v]scale=w=ih*16/9:h=-1[v1_scale];[v0_crop]scale=w=-1:h=ih*1.2[v0_scale];[v1_scale]gblur=sigma=30[v1_blur];[v1_blur]crop=out_h=iw*9/16[v1_crop];[v1_crop][v0_scale]overlay=x=(main_w-overlay_w)/2[v_overlay];[v_overlay]scale=w=1920:h=1080[v_result]\" -map [v_result] C:\\sources\\output\\hor_video.mp4```",
          "image": "tutorials/vert-hor-step8.png"
        }
      ],
      "conclusion": "You've successfully created a workflow that transforms vertical video into horizontal format with professional blur effects. This technique maintains visual quality while solving aspect ratio conversion challenges. The workflow can be extended with additional effects, color grading, or batch processing capabilities."
    },
    {
      "id": "red-nodes-compatibility",
      "title": "Understanding Red Nodes: Import Compatibility Issues",
      "description": "Learn what red nodes mean when importing workflows, why they appear, and how to fix compatibility issues between different FFmpeg versions.",
      "category": "Getting Started",
      "readTime": "5 min read",
      "date": "October 5, 2025",
      "icon": "fas fa-exclamation-triangle",
      "image": "tutorials/red-nodes.png",
      "tags": ["import", "compatibility", "nodes", "troubleshooting", "workflow"],
      "intro": "Red nodes appear when importing workflows into FFStudio and indicate compatibility issues. This tutorial explains what causes red nodes, what they mean for your workflow, and how to resolve them quickly.",
      "sections": [
        {
          "title": "What Are Red Nodes?",
          "content": "Red nodes are visual warnings that appear when you import a workflow into FFStudio. They indicate that a node from the imported workflow is not compatible with your current FFmpeg installation. This happens because:\n\n• The node name has changed between FFmpeg versions\n• The node doesn't exist in your version of FFmpeg\n• The node syntax has been modified or deprecated\n\nRed nodes prevent the workflow from running until they're fixed.",
          "image": "tutorials/red-node-example.png"
        },
        {
          "title": "Why Do Red Nodes Appear?",
          "content": "Red nodes typically appear due to version differences between the person who created the workflow and your FFmpeg installation. FFmpeg filters and options can change between versions:\n\n<strong>Common causes:</strong>\n• Filter renamed (e.g., <code>scale2ref</code> to <code>scale2ref_npp</code>)\n• Filter removed in newer versions\n• New filter not available in older versions\n• Slight name variations or typos in the original workflow",
          "image": "tutorials/version-differences.png"
        },     
        {
          "title": "Step-by-Step: Fixing Red Nodes",
          "content": "Follow this process to resolve red nodes:\n\n1. <strong>Identify the red node:</strong> Click on it to see its name and parameters\n2. <strong>Search your library:</strong> Look for similar node names in your FFmpeg installation\n3. <strong>Check compatibility:</strong> Verify the replacement node accepts the same parameters\n4. <strong>Replace the node:</strong> Delete the red node and connect the correct version\n5. <strong>Test the workflow:</strong> Run the workflow to ensure it works correctly\n\nIf multiple red nodes appear, fix them one at a time to avoid confusion."
        },
        {
          "title": "Best Case Scenario: Simple Name Differences",
          "content": "In the best case, the red node exists in your FFmpeg version but with a slightly different name. This is the easiest to fix:\n\n1. Note the name of the red node\n2. Search your FFmpeg node library for similar names\n3. Find the equivalent node in your version\n4. Replace the red node with the correct version\n\nFor example, a node named <code>colormatrix</code> might be <code>colorspace</code> in your version.",
          "image": "tutorials/simple-fix.png"
        },
        {
          "title": "Worst Case Scenario: Version Incompatibility",
          "content": "In the worst case, the node doesn't exist at all in your FFmpeg version. This requires more work:\n\n<strong>Option 1:</strong> Update or downgrade your FFmpeg to match the workflow's version\n<strong>Option 2:</strong> Find an alternative node that achieves the same result\n<strong>Option 3:</strong> Manually modify the workflow graph to work around the missing functionality\n\nCheck the FFmpeg documentation to understand what the missing node does before attempting replacements.",
          "image": "tutorials/version-upgrade.png"
        },
        {
          "title": "Prevention Tips",
          "content": "Reduce the chance of red nodes when sharing workflows:\n\n• <strong>Document your FFmpeg version:</strong> Note which version was used to create the workflow\n• <strong>Use stable filters:</strong> Prefer well-established filters over experimental ones\n• <strong>Test across versions:</strong> If possible, test your workflow on different FFmpeg versions\n• <strong>Include notes:</strong> Add comments explaining critical nodes that might change\n\nWhen importing workflows from others, always check the FFmpeg version requirements first."
        }
      ],
      "conclusion": "Red nodes indicate compatibility issues when importing workflows, usually caused by differences between FFmpeg versions. In simple cases, you only need to find and replace the node with its equivalent in your version. In complex cases, you may need to change your FFmpeg version or modify the workflow manually. Always check node names carefully and test workflows after fixing red nodes to ensure everything works correctly."
    }
  ],
  "categories": [
    "All Tutorials",
    "Getting Started",
    "Building Workflows",
    "Advanced Techniques",
    "Workflow Examples"
  ]
}
